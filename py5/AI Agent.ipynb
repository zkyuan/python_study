{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27eaaa81-d899-4376-9804-b901c471cfc4",
   "metadata": {},
   "source": [
    "# Agents是什么?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce648026-a37c-49c5-b42f-6977ea52b036",
   "metadata": {},
   "source": [
    "   大语言模型可以接受输入，可以分析&推理、可以输出文字、代码、媒体。然而，其无法像人类一样，拥有规划思考能力、运用各种工具与物理世界互动，以及拥有人类的记忆能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139e26ea-1de5-449d-b8fb-8efe64d02028",
   "metadata": {},
   "source": [
    "Al Agents是基于LLM的能够自主理解、自主规划决策、执行复杂任务的智能体。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a044c8-f029-49d7-8ef3-eaae3ff287da",
   "metadata": {},
   "source": [
    "Agent的设计目的是为了处理那些简单的语言模型可能无法直接解决的问题，尤其是当这些任务涉及到多个步骤或者需要外部数据源的情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098caf14-929d-478c-ada2-c765c8e742a3",
   "metadata": {},
   "source": [
    "+ LLM：接受输入、思考、输出\n",
    "+ 人类：LLM（接受输入、思考、输出）+**记忆** +**工具** +**规划**       ------>Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7c99e8-d15e-47de-b576-c6e9ac545df2",
   "metadata": {},
   "source": [
    "+ Agents流程图"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5e85df-64ce-4942-832c-c163aa2332c5",
   "metadata": {},
   "source": [
    "<img src=\"./img/Agents.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c513c9e-8de6-44c2-9675-9d5ae4a5c46c",
   "metadata": {},
   "source": [
    "+ **规划（Planning）** : 智能体会把大型任务**分解为子任务**，并规划执行任务的流程；智能体会对任务执行的过程进行**思考和反思**，从而决定是继续执行任务，或判断任务完结并终止运行。\n",
    "\n",
    "+ **记忆（Memory）**: 短期记忆，是指在执行任务的过程中的上下文，会在子任务的执行过程产生和暂存，在任务完结后被清空。长期记忆是长时间保留的信息，一般是指外部知识库，通常用向量数据库来存储和检索。\n",
    "\n",
    "+ **工具使用（Tools）**:为智能体配备工具 API，比如：计算器、搜索工具、代码执行器、数据库查询工具等。有了这些工具 API，智能体就可以是物理世界交互，解决实际的问题。\n",
    "\n",
    "+ **执行（Action）**: 根据规划和记忆来实施具体行动，这可能会涉及到与外部世界的互动或通过工具来完成任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f6fec6-1dcd-4138-a341-9f90e4025304",
   "metadata": {},
   "source": [
    "+ Agents决策流程图"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2968128a-1759-409c-9183-9fee8a142211",
   "metadata": {},
   "source": [
    "<img src=\"./img/Agents决策流程.png\" width=\"100%\" height=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01331cc9-8e06-431e-b235-aa9d3bf446c3",
   "metadata": {},
   "source": [
    "**场景**：假设我们有一个智能家居系统，它的任务是根据家庭成员的需求调节室内环境，比如温度和灯光。\n",
    "\n",
    "1. **感知 (Perception)**：\n",
    "   - 家庭成员通过语音助手说：“我感觉有点冷，能不能把温度调高一些？”\n",
    "   - 智能家居系统通过语音识别和情感分析技术“感知”到用户觉得房间温度太低，需要提高温度。\n",
    "2. **规划 (Planning)**：\n",
    "   - 系统根据用户的需求，规划出下一步的行动，决定如何调节房间温度。\n",
    "   - 系统可能会制定以下计划：\n",
    "     1. 检查当前的室内温度。\n",
    "     2. 根据用户的偏好和当前温度决定升高几度合适。\n",
    "     3. 调整温度设置，并告知用户。\n",
    "3. **行动 (Action)**：\n",
    "   - 系统执行计划的行动，首先检查当前温度，例如发现室温是20°C。\n",
    "   - 根据用户的偏好，将温度调高到23°C，并通过语音助手反馈给用户：“我已经将温度调高到23°C，请您稍等，温度将逐渐上升。”\n",
    "4. **观察 (Observation)**：\n",
    "   - 系统观察房间温度的变化，以及用户的反馈。如果用户在几分钟后再次说“现在温度刚刚好”，系统会感知到环境调节成功。\n",
    "   - 如果用户还觉得冷，系统可能会调整计划，进一步调高温度。\n",
    "\n",
    "### 循环：\n",
    "\n",
    "- 在每个阶段，智能家居系统都可能根据环境变化和用户反馈调整操作。例如，如果调高温度后用户依然觉得冷，系统会重新规划，进一步调整温度设置。\n",
    "- 通过这一系列的感知、规划、行动和观察，智能家居系统能够动态响应家庭成员的需求，不断调整室内环境，直到用户感觉舒适为止。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10119a3d-42d5-4021-9b03-a45861aba2bb",
   "metadata": {},
   "source": [
    "### 规划（Planing）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441be86c-46aa-41fa-b3f4-cdaabd3ee1be",
   "metadata": {},
   "source": [
    "规划，可以为理解**观察和思考**。如果用人类来类比，当我们接到一个任务，我们的思维模式可能会像下面这样:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cee976-ec58-41c1-b396-eb68f4d373d8",
   "metadata": {},
   "source": [
    "+ 1、首先会思考怎么完成这个任务。\n",
    "\n",
    "+ 2、然后会审视手头上所拥有的工具，以及如何使用这些工具高效地达成目的。\n",
    "\n",
    "+ 3、再会把任务拆分成子任务。(就像咱们做思维导图一样。)\n",
    "\n",
    "+ 4、在执行任务的时候，我们会对执行过程进行反思和完善，吸取教训以完善未来的步骤。\n",
    "\n",
    "+ 5、执行过程中思考任务何时可以终止。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aa69bc-f39d-499c-aa4c-1c733f23e7d2",
   "metadata": {},
   "source": [
    "这是**人类的规划能力**，我们希望智能体也拥有这样的思维模式，因此可以通过 LLM 提示工程，为智能体赋予这样的思维模式。在智能体中，最重要的是让 LLM 具备这以下两个能力："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3113f7d-2a47-4529-bdb5-4a3313ac55c1",
   "metadata": {},
   "source": [
    "#### 子任务分解"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d31ec5-bce8-44bd-9c3b-60c56295db61",
   "metadata": {},
   "source": [
    "通过LLM使得智能体可以把大型任务分解为更小的、更可控的子任务，从而能够有效完成复杂的任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c6ee0a-f245-4b0c-8952-6f10a6b68ac5",
   "metadata": {},
   "source": [
    "##### 思维链（Chain of Thoughts, CoT）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8042600-9c75-40ad-99c3-01c69a45364c",
   "metadata": {},
   "source": [
    "**思维链已经是一种比较标准的提示技术**，能显著提升 LLM 完成复杂任务的效果。当我们对 LLM 这样要求「think step by step」，会发现 LLM 会把问题分解成多个步骤，一步一步思考和解决，能使得输出的结果更加准确。这是一种线性的思维方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e33b798-dae8-4383-9cff-0d447b7e2fc5",
   "metadata": {},
   "source": [
    "##### 思维树（Tree-of-thought, ToT）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864c189b-d4f8-4664-8e27-0d98641c050d",
   "metadata": {},
   "source": [
    "对 CoT 的进一步扩展，在思维链的每一步，推理出多个分支，拓扑展开成一棵思维树。使用启发式方法评估每个推理分支对问题解决的贡献。选择搜索算法，使用**广度优先搜索（BFS）或深度优先搜索（DFS**等算法来探索思维树，并进行前瞻和回溯。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7d54ee-11b8-40a1-9df5-5b58d2e806b3",
   "metadata": {},
   "source": [
    "<img src=\"./img/思维树框架原理.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df803bde-5408-4631-a832-a97b514e6b1a",
   "metadata": {},
   "source": [
    "#### 反思与改进"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5ad715-2d2e-494f-8a63-e007b0fe1866",
   "metadata": {},
   "source": [
    "Agent对过去的行动进行自我批评和反思，从错误中学习并改进未来的步骤，从而提高最终结果的质量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411d1e06-19e1-4823-863a-e850c2b0aaec",
   "metadata": {},
   "source": [
    "在实际任务中，试错是不可避免的，而自我反思在这个过程中起着至关重要的作用。它允许 Agent 通过改进过去的行动决策和纠正以前的错误来进行迭代改进。\n",
    "\n",
    "反思是 Agent 对事情进行更高层次、更抽象思考的结果。反思是周期性生成的，当Agent感知到的最新事件的重要性评分之和超过一定阈值时，就会生成反思。这可以类比为我们常用的成语“三思而后行”，做重大决策的时候，我们会反思自己先前的决策。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4aebfd-3960-4e32-a12b-fa815cd84f5d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#####   ReAct框架"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c03d62-43f0-4084-a006-316f1695c932",
   "metadata": {},
   "source": [
    "《ReAct: Synergizing Reasoning and Acting in Language Models》 这篇论文提出一种用于增强大型语言模型的方法，它通过结合推理（Reasoning）和行动（Acting）来增强推理和决策的效果。\n",
    "\n",
    "参考:https://react-lm.github.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b714152-fbbb-45f5-8a13-65a00dc5afd4",
   "metadata": {},
   "source": [
    "<img src=\"./img/通过不同框架解决具体问题.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a02a183-484b-48b1-96c0-e3251cca73eb",
   "metadata": {},
   "source": [
    "+ 标准（Standard）:\n",
    "  \n",
    "直接给出错误的答案——iPod。没有提供任何推理过程或外部交互，直接给出答案。\n",
    "\n",
    "错误的答案：iPod\n",
    "\n",
    "+ 仅推理（Reason only):\n",
    "  \n",
    "尝试通过逐步推理来解决问题，但没有与外部环境交互来验证信息。错误地推断出答案是iPhone、 iPad 1Pod Touch。\n",
    "\n",
    "错误的答案：Phone、iPad、iPod、Touch\n",
    "\n",
    "+ 仅行动（Act only）:\n",
    "  \n",
    "通过与外部环境（如维基百科）的一系列交互来获取信息，尝试多次搜索（搜索 “Apple Remote”，“Front Row” 等），但缺乏推理支持，未能综合这些观察结果后得出正确答案。认\n",
    "为需要结束搜索。\n",
    "\n",
    "错误的决策：结束搜索\n",
    "\n",
    "+ ReAct:\n",
    "  \n",
    "组合推理和行动。首先通过推理确定搜索 Apple Remote （苹果遥控器），并从外部环境中观察结果。随着推理的深入，识别出需要搜索 Front Row（软件）。在几轮交互后，通过进一步推理，准确得出答案“键盘功能键”\n",
    "\n",
    "正确的答案：键盘功能键"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14119b41-94ed-408c-a9d8-d6ef098fbb9f",
   "metadata": {},
   "source": [
    "为什么结合推理和行动，就会有效增强 LLM 完成任务的能力？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b6d255-00f0-4f61-9781-62f0e11de002",
   "metadata": {},
   "source": [
    "<img src=\"./img/React工作简图.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967f850c-8f47-44c5-a978-5f59be47260b",
   "metadata": {},
   "source": [
    "+ 仅推理（Reasoning Only）：LLM 仅仅基于已有的知识进行推理，生成答案回答这个问题。很显然，如果 LLM 本身不具备这些知识，可能会出现幻觉，胡乱回答一通。\n",
    "\n",
    "+ 仅行动（Acting Only）：大模型不加以推理，仅使用工具（比如搜索引擎）搜索这个问题，得出来的将会是海量的资料，不能直接回到这个问题。\n",
    "\n",
    "+ 推理+行动（Reasoning and Acting）：LLM 首先会基于已有的知识，并审视拥有的工具。当发现已有的知识不足以回答这个问题，则会调用工具，比如：搜索工具、生成报告等，然后得到新的信息，基于新的信息重复进行推理和行动，直到完成这个任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eee078-f441-4051-b539-3fd41dea2d5d",
   "metadata": {},
   "source": [
    "### 记忆（Memory）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede81b2e-898e-4515-b2a3-c1b181c98ce0",
   "metadata": {},
   "source": [
    "**生活中的记忆机制:**\n",
    "\n",
    "+ 感觉记忆（Sensory Memory）：这是记忆的最早阶段，提供在原始刺激结束后保留感官信息（视觉、听觉等）的印象的能力。感觉记忆通常只持续几秒钟。\n",
    "\n",
    "+ 短期记忆（或工作记忆）：这是一种持续时间较短的记忆，能够暂时存储和处理有限数量的信息。例如，记住一个电话号码直到拨打完毕。\n",
    "\n",
    "+ 长期记忆：这是一种持续时间较长的记忆，可以存储大量信息，从几分钟到一生。长期记忆可以进一步分为显性记忆和隐性记忆。显性记忆，可以有意识地回忆和表达的信息，显性记忆又可以分为情景记忆（个人经历的具体事件）和语义记忆（一般知识和概念）。隐性记忆，这种记忆通常是无意识的，涉及技能和习惯，如骑自行车或打字。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b8f99d-9b3c-4362-9be7-89fdaf50690a",
   "metadata": {},
   "source": [
    "**智能体中的记忆机制:**\n",
    "+ 形成记忆:大模型在大量包含世界知识的数据集上进行预训练。在预训练中，大模型通过调整神经元的权重来学习理解和生成人类语言，这可以被视为“记忆”的形成过程。通过使用深度学习和梯度下降等技术，大模型可以不断提高基于预测或生产文本的能力，进而形成世界记忆或长期记忆\n",
    "\n",
    "+ 短期记忆：在当前任务执行过程中所产生的信息，比如某个工具或某个子任务执行的结果，会写入短期记忆中。记忆在当前任务过程中产生和暂存，在任务完结后被清空。\n",
    "\n",
    "+ 长期记忆：长期记忆是长时间保留的信息。一般是指外部知识库，通常用向量数据库来存储和检索。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d86d6d1-5479-463f-8911-f83c1023992f",
   "metadata": {},
   "source": [
    "### 工具使用（Tools/Toolkits）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab557ef0-518d-418e-9bc1-0991c54044ae",
   "metadata": {},
   "source": [
    "Agent可以通过学习调用外部API来获取模型权重中所缺少的额外信息，这些信息包括当前信息、代码执行能力和访问专有信息源等。这对于预训练后难以修改的模型权重来说是非常重要的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7292c2-46ee-4b8e-ba90-dbff5a50aef3",
   "metadata": {},
   "source": [
    "掌握使用工具是人类最独特和重要的特质之一。我们通过创造、修改和利用外部工具来突破我们身体和认知的限制。同样地，我们也可以为语言模型（LLM）提供外部工具来显著提升其能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683e851f-fd19-4964-bd15-d6d20a0cd8b9",
   "metadata": {},
   "source": [
    "<img src=\"./img/tools与toolkits.png\" width=\"100%\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2b620d-1b4a-4336-b105-da0da45effc8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 第一个agent"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cbc56b70-11c8-459a-8b81-ba7c8c5c2f7f",
   "metadata": {},
   "source": [
    "v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8d56114-472a-40c0-bc51-dd2287902ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m我需要使用搜索引擎来找到中国现任主席的名字，然后使用计算器来计算他的年龄的平方。\n",
      "Action: Search\n",
      "Action Input: \"中国现任主席\"\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3mXi Jinping\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m现任中国主席是习近平\n",
      "Action: Calculator\n",
      "Action Input: 68^2\u001B[0m\n",
      "Observation: \u001B[33;1m\u001B[1;3mAnswer: 4624\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m我现在知道了中国现任主席是习近平，他的年龄的平方是4624。\n",
      "Final Answer: 中国现任主席是习近平，他的年龄的平方是4624。\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "中国现任主席是习近平，他的年龄的平方是4624。\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain_community.agent_toolkits.load_tools import load_tools\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#定义llm\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "\n",
    "tools = load_tools([\"serpapi\",\"llm-math\"], llm=llm)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, # 这里有不同的类型\n",
    "    verbose=True,#是否打印日志\n",
    ")\n",
    "\n",
    "print(agent.run(\"请问现任的中国主席是谁？他的年龄的平方是多少? 请用中文告诉我这两个问题的答案\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d476cd6-058b-40fe-83ef-21250b3bfddb",
   "metadata": {},
   "source": [
    "V0.2\n",
    "参考:https://python.langchain.com/v0.2/docs/how_to/agent_executor/#create-the-agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2f237a-2ab5-401d-97fb-f3073de0fe90",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 如何使用Tools/Toolkits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27666e5-bc45-445e-a842-5c2dc4274388",
   "metadata": {},
   "source": [
    "参考:https://python.langchain.com/v0.2/docs/integrations/tools/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daf35f6-2937-4dec-96e2-32132050eda0",
   "metadata": {},
   "source": [
    "#### Dall-E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af316585-0397-4c9c-9c77-c736597ce942",
   "metadata": {},
   "source": [
    "参考:https://python.langchain.com/v0.2/docs/integrations/tools/dalle_image_generator/#run-as-a-chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "432f7db4-5ea8-4eb1-aed7-eae2725c15f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_community'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_community\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mchat_models\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ChatOpenAI\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdotenv\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_dotenv\n\u001B[1;32m      3\u001B[0m load_dotenv()\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'langchain_community'"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-4\",\n",
    ")\n",
    "from langchain_community.agent_toolkits.load_tools import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "\n",
    "tools = load_tools([\"dalle-image-generator\"])\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    verbose=True\n",
    ")\n",
    "# 这是一只可爱的英国短毛小猫的特写，圆脸，大眼睛，蓬松的金棕色皮毛，腹部较浅。\n",
    "# 小猫有小而圆的耳朵，粉红色的鼻子和黑色的爪垫。它躺在柔软的、有纹理的表面上，\n",
    "# 好奇地微微倾斜着头，向上凝视着。背景稍微模糊，将焦点集中在小猫可爱的特征上，\n",
    "# 整体氛围温暖舒适。\n",
    "output = agent.run(\"A close-up portrait of an adorable British Shorthair kitten with a round face, big expressive eyes, and a fluffy, golden-brown fur coat with a lighter underbelly. The kitten has small, rounded ears, a pink nose, and black paw pads. It is lying down on a soft, textured surface, with a curious and slightly tilted head, gazing upwards. The background is slightly blurred, drawing focus to the kitten's cute features, and the overall atmosphere is warm and cozy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b076f3-a861-4be0-9d78-19e4b42b3897",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Json工具包"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2579bb0f-15fc-4a6a-a72a-89228ee88c13",
   "metadata": {},
   "source": [
    "参考1:https://github.com/openai/openai-openapi/blob/master/openapi.yaml\n",
    "\n",
    "参考2:https://python.langchain.com/v0.2/docs/integrations/tools/json/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e79cf74-cd19-4118-b313-d5ada92ae72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mAction: json_spec_list_keys\n",
      "Action Input: data\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3m['openapi', 'info', 'servers', 'tags', 'paths', 'components', 'security', 'x-oaiMeta']\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m I should look at the keys in the paths key to see what paths are available\n",
      "Action: json_spec_list_keys\n",
      "Action Input: data[\"paths\"]\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3m['/chat/completions', '/completions', '/images/generations', '/images/edits', '/images/variations', '/embeddings', '/audio/speech', '/audio/transcriptions', '/audio/translations', '/files', '/files/{file_id}', '/files/{file_id}/content', '/uploads', '/uploads/{upload_id}/parts', '/uploads/{upload_id}/complete', '/uploads/{upload_id}/cancel', '/fine_tuning/jobs', '/fine_tuning/jobs/{fine_tuning_job_id}', '/fine_tuning/jobs/{fine_tuning_job_id}/events', '/fine_tuning/jobs/{fine_tuning_job_id}/cancel', '/fine_tuning/jobs/{fine_tuning_job_id}/checkpoints', '/models', '/models/{model}', '/moderations', '/assistants', '/assistants/{assistant_id}', '/threads', '/threads/{thread_id}', '/threads/{thread_id}/messages', '/threads/{thread_id}/messages/{message_id}', '/threads/runs', '/threads/{thread_id}/runs', '/threads/{thread_id}/runs/{run_id}', '/threads/{thread_id}/runs/{run_id}/submit_tool_outputs', '/threads/{thread_id}/runs/{run_id}/cancel', '/threads/{thread_id}/runs/{run_id}/steps', '/threads/{thread_id}/runs/{run_id}/steps/{step_id}', '/vector_stores', '/vector_stores/{vector_store_id}', '/vector_stores/{vector_store_id}/files', '/vector_stores/{vector_store_id}/files/{file_id}', '/vector_stores/{vector_store_id}/file_batches', '/vector_stores/{vector_store_id}/file_batches/{batch_id}', '/vector_stores/{vector_store_id}/file_batches/{batch_id}/cancel', '/vector_stores/{vector_store_id}/file_batches/{batch_id}/files', '/batches', '/batches/{batch_id}', '/batches/{batch_id}/cancel', '/organization/audit_logs', '/organization/invites', '/organization/invites/{invite_id}', '/organization/users', '/organization/users/{user_id}', '/organization/projects', '/organization/projects/{project_id}', '/organization/projects/{project_id}/archive', '/organization/projects/{project_id}/users', '/organization/projects/{project_id}/users/{user_id}', '/organization/projects/{project_id}/service_accounts', '/organization/projects/{project_id}/service_accounts/{service_account_id}', '/organization/projects/{project_id}/api_keys', '/organization/projects/{project_id}/api_keys/{key_id}']\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m I should look at the keys in the /completions path to see what parameters are required\n",
      "Action: json_spec_list_keys\n",
      "Action Input: data[\"paths\"][\"/completions\"]\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3m['post']\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m I should look at the keys in the post key to see what parameters are required\n",
      "Action: json_spec_list_keys\n",
      "Action Input: data[\"paths\"][\"/completions\"][\"post\"]\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3m['operationId', 'tags', 'summary', 'requestBody', 'responses', 'x-oaiMeta']\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m I should look at the keys in the requestBody key to see what parameters are required\n",
      "Action: json_spec_list_keys\n",
      "Action Input: data[\"paths\"][\"/completions\"][\"post\"][\"requestBody\"]\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3m['required', 'content']\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m I should look at the keys in the content key to see what parameters are required\n",
      "Action: json_spec_list_keys\n",
      "Action Input: data[\"paths\"][\"/completions\"][\"post\"][\"requestBody\"][\"content\"]\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3m['application/json']\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m I should look at the keys in the application/json key to see what parameters are required\n",
      "Action: json_spec_list_keys\n",
      "Action Input: data[\"paths\"][\"/completions\"][\"post\"][\"requestBody\"][\"content\"][\"application/json\"]\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3m['schema']\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m I should look at the keys in the schema key to see what parameters are required\n",
      "Action: json_spec_list_keys\n",
      "Action Input: data[\"paths\"][\"/completions\"][\"post\"][\"requestBody\"][\"content\"][\"application/json\"][\"schema\"]\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3m['$ref']\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m I should look at the keys in the $ref key to see what parameters are required\n",
      "Action: json_spec_list_keys\n",
      "Action Input: data[\"paths\"][\"/completions\"][\"post\"][\"requestBody\"][\"content\"][\"application/json\"][\"schema\"][\"$ref\"]\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3mValueError('Value at path `data[\"paths\"][\"/completions\"][\"post\"][\"requestBody\"][\"content\"][\"application/json\"][\"schema\"][\"$ref\"]` is not a dict, get the value directly.')\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m I should look at the value at the $ref key to see what parameters are required\n",
      "Action: json_spec_get_value\n",
      "Action Input: data[\"paths\"][\"/completions\"][\"post\"][\"requestBody\"][\"content\"][\"application/json\"][\"schema\"][\"$ref\"]\u001B[0m\n",
      "Observation: \u001B[33;1m\u001B[1;3m#/components/schemas/CreateCompletionRequest\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m I should look at the keys in the #/components/schemas/CreateCompletionRequest key to see what parameters are required\n",
      "Action: json_spec_list_keys\n",
      "Action Input: data[\"components\"][\"schemas\"][\"CreateCompletionRequest\"]\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3m['type', 'properties', 'required']\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m I should look at the keys in the properties key to see what parameters are required\n",
      "Action: json_spec_list_keys\n",
      "Action Input: data[\"components\"][\"schemas\"][\"CreateCompletionRequest\"][\"properties\"]\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3m['model', 'prompt', 'best_of', 'echo', 'frequency_penalty', 'logit_bias', 'logprobs', 'max_tokens', 'n', 'presence_penalty', 'seed', 'stop', 'stream', 'stream_options', 'suffix', 'temperature', 'top_p', 'user']\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m I should look at the keys in the required key to see what parameters are required\n",
      "Action: json_spec_list_keys\n",
      "Action Input: data[\"components\"][\"schemas\"][\"CreateCompletionRequest\"][\"required\"]\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3mValueError('Value at path `data[\"components\"][\"schemas\"][\"CreateCompletionRequest\"][\"required\"]` is not a dict, get the value directly.')\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m I should look at the value at the required key to see what parameters are required\n",
      "Action: json_spec_get_value\n",
      "Action Input: data[\"components\"][\"schemas\"][\"CreateCompletionRequest\"][\"required\"]\u001B[0m\n",
      "Observation: \u001B[33;1m\u001B[1;3m['model', 'prompt']\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m I now know the final answer\n",
      "Final Answer: ['model', 'prompt']\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"['model', 'prompt']\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "from langchain_community.agent_toolkits import JsonToolkit, create_json_agent\n",
    "from langchain_community.tools.json.tool import JsonSpec\n",
    "from langchain_openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "with open(\"/Users/yuejunzhang/Data analysis/AI大模型/day08Agent/openapi.yaml\") as f:\n",
    "    data = yaml.load(f, Loader=yaml.FullLoader)\n",
    "json_spec = JsonSpec(dict_=data, max_value_length=4000)\n",
    "json_toolkit = JsonToolkit(spec=json_spec)\n",
    "\n",
    "json_agent_executor = create_json_agent(\n",
    "    llm=OpenAI(temperature=0), toolkit=json_toolkit, verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "json_agent_executor.run(\n",
    "    \"What are the required parameters in the request body to the /completions endpoint?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d268c6-06b1-4423-9c45-003c07e9976e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 给Agent添加记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f599794-668c-48a0-8813-aa38915f4e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain/chains/llm_math/base.py:56: UserWarning: Directly instantiating an LLMMathChain with an llm is deprecated. Please instantiate with llm_chain argument or using the from_llm class method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tool(name='Search', description='useful for when you need to answer questions about current events or the current state of the world', func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='ee37d0eae22dbd837968f7c72b651c2feb2f3c1a3987d3cc51a11655ccbe21d4', aiosession=None)>), Tool(name='Calculator', description='useful for when you need to answer questions about math', func=<bound method Chain.run of LLMMathChain(verbose=True, llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['question'], template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x14f566d10>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x14f591cd0>, model_name='gpt-4-1106-preview', temperature=0.0, openai_api_key='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', openai_proxy='')), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x14f566d10>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x14f591cd0>, model_name='gpt-4-1106-preview', temperature=0.0, openai_api_key='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', openai_proxy=''))>)]\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m作为一个AI，我没有访问您个人信息的权限，所以我不知道您的名字。如果您愿意告诉我，我可以称呼您。\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m作为AI，我可以回顾我们的对话记录。到目前为止，我们的对话内容如下：\n",
      "\n",
      "1. 您问我：“我叫什么名字？”\n",
      "2. 我回答说，作为AI，我没有访问您个人信息的权限，所以我不知道您的名字，并提出如果您愿意告诉我，我可以称呼您。\n",
      "3. 您接着问：“好厉害，刚才我们都聊了什么？”\n",
      "\n",
      "这就是我们目前为止的对话内容。如果您有其他问题或需要帮助，请随时告诉我！\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'作为AI，我可以回顾我们的对话记录。到目前为止，我们的对话内容如下：\\n\\n1. 您问我：“我叫什么名字？”\\n2. 我回答说，作为AI，我没有访问您个人信息的权限，所以我不知道您的名字，并提出如果您愿意告诉我，我可以称呼您。\\n3. 您接着问：“好厉害，刚才我们都聊了什么？”\\n\\n这就是我们目前为止的对话内容。如果您有其他问题或需要帮助，请随时告诉我！'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.chains import LLMMathChain\n",
    "from langchain.prompts import  MessagesPlaceholder\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "llm=ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    )\n",
    "#构建一个搜索工具\n",
    "search = SerpAPIWrapper()\n",
    "#创建一个数学计算工具\n",
    "llm_math_chain = LLMMathChain(\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events or the current state of the world\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Calculator\",\n",
    "        func=llm_math_chain.run,\n",
    "        description=\"useful for when you need to answer questions about math\"\n",
    "    ),\n",
    "]\n",
    "print(tools)\n",
    "\n",
    "\n",
    "#记忆组件\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "agent_chain = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,#处理解析错误\n",
    "    agent_kwargs={\n",
    "        \"extra_prompt_messages\":[MessagesPlaceholder(variable_name=\"chat_history\"),MessagesPlaceholder(variable_name=\"agent_scratchpad\")],\n",
    "    },\n",
    "    memory=memory #记忆组件\n",
    "    )\n",
    "agent_chain.run(\"我叫什么名字？\")\n",
    "\n",
    "agent_chain.run(\"好厉害，刚才我们都聊了什么？\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa1bad3-3c1c-4761-846b-5bd408f46e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
