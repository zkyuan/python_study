"""
 * @author: zkyuan
 * @date: 2025/4/10 21:39
 * @description:

ä»¥ä¸‹æ˜¯client.py ä»£ç è¯¦è§£ï¼Œä»£ç æ ¸å¿ƒåŠŸèƒ½ï¼š

åˆå§‹åŒ– MCP å®¢æˆ·ç«¯

æä¾›ä¸€ä¸ªå‘½ä»¤è¡Œäº¤äº’ç•Œé¢

æ¨¡æ‹Ÿ MCP æœåŠ¡å™¨è¿æ¥

æ”¯æŒç”¨æˆ·è¾“å…¥æŸ¥è¯¢å¹¶è¿”å›ã€Œæ¨¡æ‹Ÿå›å¤ã€

æ”¯æŒå®‰å…¨é€€å‡º
"""
import asyncio  # è®©ä»£ç æ”¯æŒå¼‚æ­¥æ“ä½œ
import os

from dotenv import load_dotenv
from mcp import ClientSession  # MCP å®¢æˆ·ç«¯ä¼šè¯ç®¡ç†
from contextlib import AsyncExitStack  # èµ„æºç®¡ç†ï¼ˆç¡®ä¿å®¢æˆ·ç«¯å…³é—­æ—¶é‡Šæ”¾èµ„æºï¼‰

from openai import OpenAI

# åŠ è½½ .env æ–‡ä»¶ï¼Œç¡®ä¿ API Key å—åˆ°ä¿æŠ¤
load_dotenv()


class MCPClient:
    def __init__(self):
        """åˆå§‹åŒ– MCP å®¢æˆ·ç«¯"""
        self.exit_stack = AsyncExitStack()
        self.openai_api_key = os.getenv("OPENAI_API_KEY")  # è¯»å– OpenAI API Key
        self.base_url = os.getenv("BASE_URL_GPT")  # è¯»å– BASE YRL
        self.model = os.getenv("MODEL_GPT")  # è¯»å– model

        if not self.openai_api_key:
            raise ValueError("âŒ æœªæ‰¾åˆ° OpenAI API Keyï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® OPENAI_API_KEY")

        self.client = OpenAI(api_key=self.openai_api_key, base_url=self.base_url)

    async def process_query(self, query: str) -> str:
        """è°ƒç”¨ OpenAI API å¤„ç†ç”¨æˆ·æŸ¥è¯¢"""
        messages = [{"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå¸®åŠ©ç”¨æˆ·å›ç­”é—®é¢˜ã€‚"},
                    {"role": "user", "content": query}]

        try:
            # å°† OpenAI API å˜æˆå¼‚æ­¥ä»»åŠ¡ï¼Œé˜²æ­¢ç¨‹åºå¡é¡¿
            response = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    max_tokens=1000,
                    temperature=0.3,
                )
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"âš ï¸ è°ƒç”¨ OpenAI API æ—¶å‡ºé”™: {str(e)}"


    async def chat_loop(self):
        """è¿è¡Œäº¤äº’å¼èŠå¤©å¾ªç¯"""
        print("\nğŸ“¢ MCP å®¢æˆ·ç«¯å·²å¯åŠ¨ï¼è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
        while True:
            try:
                query = input("\nğŸ“ Query: ").strip()
                if query.lower() == 'quit' or query.lower() == 'exit':
                    print("\nğŸ‘‹ é€€å‡ºèŠå¤©...")
                    break
                response = await self.process_query(query)  # å‘é€ç”¨æˆ·è¾“å…¥åˆ° OpenAI API
                print(f"\nğŸ¤– OpenAI: {response}")
            except Exception as e:
                print(f"\nâš ï¸ å‘ç”Ÿé”™è¯¯: {str(e)}")

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        await self.exit_stack.aclose()


async def main():
    client = MCPClient()
    try:
        await client.chat_loop()
    finally:
        await client.cleanup()


if __name__ == "__main__":
    asyncio.run(main())
