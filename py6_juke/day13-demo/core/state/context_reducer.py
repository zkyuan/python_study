# å¯¼å…¥æ‰€éœ€çš„æ¨¡å—å’Œç±»
import operator
from contextlib import contextmanager
from typing import Annotated, Sequence

import httpx
from langchain_core.messages import BaseMessage
from langchain_core.messages import HumanMessage
from langchain_core.messages import ToolMessage
from langchain_core.pydantic_v1 import BaseModel
from langchain_core.runnables import RunnableConfig
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.channels.context import Context
from langgraph.graph import END, StateGraph, START
from langgraph.prebuilt import ToolInvocation
from langgraph.prebuilt import ToolNode

# åˆå§‹åŒ–ä¸€ä¸ªChatOpenAIæ¨¡å‹å®ä¾‹ï¼Œè®¾ç½®æ¸©åº¦ä¸º0
model = ChatOpenAI(temperature=0)


# å®šä¹‰ä¸€ä¸ªä»£ç†ä¸Šä¸‹æ–‡ç±»ï¼Œç»§æ‰¿è‡ªBaseModel
class AgentContext(BaseModel):
    class Config:
        arbitrary_types_allowed = True

    # å®šä¹‰ä¸€ä¸ªhttpxå®¢æˆ·ç«¯ä¼šè¯å±æ€§
    httpx_session: httpx.Client


# åˆ›å»ºä¸€ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œç”¨äºåˆ›å»ºå’Œç®¡ç†AgentContextå®ä¾‹
@contextmanager
def make_agent_context(config: RunnableConfig):
    # åˆ›å»ºä¸€ä¸ªhttpxå®¢æˆ·ç«¯ä¼šè¯
    session = httpx.Client()
    try:
        # ç”Ÿæˆä¸€ä¸ªåŒ…å«httpxä¼šè¯çš„AgentContextå®ä¾‹
        yield AgentContext(httpx_session=session)
    finally:
        # å…³é—­httpxä¼šè¯
        session.close()


# å®šä¹‰ä»£ç†çŠ¶æ€ç±»ï¼ŒåŒ…å«æ¶ˆæ¯åºåˆ—å’Œä¸Šä¸‹æ–‡
class AgentState(BaseModel):
    messages: Annotated[Sequence[BaseMessage], operator.add]
    context: Annotated[AgentContext, Context(make_agent_context)]


# å®šä¹‰ä¸€ä¸ªå·¥å…·å‡½æ•°ï¼Œç”¨äºæœç´¢æŸ¥è¯¢
@tool
def search(query: str):
    """Call to surf the web."""
    # è¿™æ˜¯å®é™…å®ç°çš„å ä½ç¬¦
    # ä¸è¦è®©LLMçŸ¥é“è¿™ä¸ªğŸ˜Š
    return ["The answer to your question lies within."]


# åˆ›å»ºä¸€ä¸ªåŒ…å«æœç´¢å·¥å…·çš„å·¥å…·æ‰§è¡Œå™¨
tools = [search]
tool_executor = ToolNode(tools)


# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºç¡®å®šæ˜¯å¦ç»§ç»­
def should_continue(state):
    messages = state.messages
    last_message = messages[-1]
    # å¦‚æœæ²¡æœ‰å‡½æ•°è°ƒç”¨ï¼Œåˆ™ç»“æŸ
    if not last_message.tool_calls:
        return "end"
    # å¦åˆ™ç»§ç»­
    else:
        return "continue"


# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºè°ƒç”¨æ¨¡å‹
def call_model(state):
    # ä½¿ç”¨ä¸Šä¸‹æ–‡å€¼
    req = state.context.httpx_session.get("https://www.langchain.com/")
    assert req.status_code == 200, req
    messages = state.messages
    response = model.invoke(messages)
    # è¿”å›ä¸€ä¸ªåˆ—è¡¨ï¼Œå› ä¸ºè¿™å°†è¢«æ·»åŠ åˆ°ç°æœ‰åˆ—è¡¨ä¸­
    return {"messages": [response]}


# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºæ‰§è¡Œå·¥å…·
def call_tool(state):
    messages = state.messages
    # æ ¹æ®ç»§ç»­æ¡ä»¶
    # æˆ‘ä»¬çŸ¥é“æœ€åä¸€æ¡æ¶ˆæ¯æ¶‰åŠå‡½æ•°è°ƒç”¨
    last_message = messages[-1]
    # æˆ‘ä»¬ä»å‡½æ•°è°ƒç”¨ä¸­æ„å»ºä¸€ä¸ªToolInvocation
    tool_call = last_message.tool_calls[0]
    action = ToolInvocation(
        tool=tool_call["name"],
        tool_input=tool_call["args"],
    )
    # æˆ‘ä»¬è°ƒç”¨å·¥å…·æ‰§è¡Œå™¨å¹¶è¿”å›å“åº”
    response = tool_executor.invoke(action)
    # æˆ‘ä»¬ä½¿ç”¨å“åº”åˆ›å»ºä¸€ä¸ªToolMessage
    tool_message = ToolMessage(
        content=str(response), name=action.tool, tool_call_id=tool_call["id"]
    )
    # è¿”å›ä¸€ä¸ªåˆ—è¡¨ï¼Œå› ä¸ºè¿™å°†è¢«æ·»åŠ åˆ°ç°æœ‰åˆ—è¡¨ä¸­
    return {"messages": [tool_message]}


# å®šä¹‰ä¸€ä¸ªæ–°çš„çŠ¶æ€å›¾
workflow = StateGraph(AgentState)

# å®šä¹‰æˆ‘ä»¬å°†åœ¨å…¶ä¹‹é—´å¾ªç¯çš„ä¸¤ä¸ªèŠ‚ç‚¹
workflow.add_node("agent", call_model)
workflow.add_node("action", call_tool)

# å°†å…¥å£ç‚¹è®¾ç½®ä¸º`agent`
# è¿™æ„å‘³ç€è¿™æ˜¯ç¬¬ä¸€ä¸ªè¢«è°ƒç”¨çš„èŠ‚ç‚¹
workflow.add_edge(START, "agent")

# æˆ‘ä»¬ç°åœ¨æ·»åŠ ä¸€ä¸ªæ¡ä»¶è¾¹
workflow.add_conditional_edges(
    # é¦–å…ˆï¼Œæˆ‘ä»¬å®šä¹‰èµ·å§‹èŠ‚ç‚¹ã€‚æˆ‘ä»¬ä½¿ç”¨`agent`ã€‚
    # è¿™æ„å‘³ç€è¿™äº›è¾¹æ˜¯åœ¨è°ƒç”¨`agent`èŠ‚ç‚¹ä¹‹åé‡‡å–çš„ã€‚
    "agent",
    # æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä¼ å…¥ç¡®å®šä¸‹ä¸€ä¸ªè¢«è°ƒç”¨èŠ‚ç‚¹çš„å‡½æ•°ã€‚
    should_continue,
    # æœ€åæˆ‘ä»¬ä¼ å…¥ä¸€ä¸ªæ˜ å°„ã€‚
    # é”®æ˜¯å­—ç¬¦ä¸²ï¼Œå€¼æ˜¯å…¶ä»–èŠ‚ç‚¹ã€‚
    # ENDæ˜¯ä¸€ä¸ªç‰¹æ®ŠèŠ‚ç‚¹ï¼Œè¡¨ç¤ºå›¾åº”è¯¥ç»“æŸã€‚
    # å°†è°ƒç”¨`should_continue`ï¼Œç„¶åå…¶è¾“å‡ºå°†ä¸æ­¤æ˜ å°„ä¸­çš„é”®åŒ¹é…ã€‚
    # æ ¹æ®åŒ¹é…çš„ç»“æœï¼Œè°ƒç”¨ç›¸åº”çš„èŠ‚ç‚¹ã€‚
    {
        # å¦‚æœæ˜¯`action`ï¼Œåˆ™è°ƒç”¨å·¥å…·èŠ‚ç‚¹ã€‚
        "continue": "action",
        # å¦åˆ™ç»“æŸã€‚
        "end": END,
    },
)

# æˆ‘ä»¬ç°åœ¨ä»`tools`åˆ°`agent`æ·»åŠ ä¸€ä¸ªæ­£å¸¸è¾¹ã€‚
# è¿™æ„å‘³ç€åœ¨è°ƒç”¨`tools`ä¹‹åï¼Œè°ƒç”¨`agent`èŠ‚ç‚¹ã€‚
workflow.add_edge("action", "agent")

# æœ€åï¼Œæˆ‘ä»¬ç¼–è¯‘å®ƒï¼
# è¿™å°†å…¶ç¼–è¯‘ä¸ºLangChain Runnableï¼Œ
# è¿™æ„å‘³ç€ä½ å¯ä»¥åƒä½¿ç”¨å…¶ä»–runnableä¸€æ ·ä½¿ç”¨å®ƒ
app = workflow.compile()

# åˆ›å»ºä¸€äº›åˆå§‹æ¶ˆæ¯
initial_messages = [
    HumanMessage(content="langchainæœ€æ–°ç‰ˆæœ¬")
]

# åˆ›å»ºåˆå§‹çŠ¶æ€
initial_state = AgentState(
    messages=initial_messages,
    context=AgentContext(httpx_session=httpx.Client())
)

# è°ƒç”¨app.invokeï¼Œå¹¶ä¼ é€’åˆå§‹çŠ¶æ€
result = app.invoke(initial_state)
print(result)

# å‡è®¾ app æ˜¯ä½ çš„å·¥ä½œæµåº”ç”¨å®ä¾‹
graph_png = app.get_graph().draw_mermaid_png()
# å°†ç”Ÿæˆçš„å›¾ç‰‡ä¿å­˜åˆ°æ–‡ä»¶
with open("context_reducer.png", "wb") as f:
    f.write(graph_png)
